{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVZg8br9ejRx"
      },
      "source": [
        "# **Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYN0ofDSciIR"
      },
      "source": [
        "import nltk\n",
        "from os import getcwd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x05kyMLmdILL",
        "outputId": "0f1daa1b-9c52-4c9d-c7da-08c3600af68e"
      },
      "source": [
        "nltk.download('twitter_samples')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vF5_Ks7wdMci",
        "outputId": "7279e586-d267-4ce0-d7a0-00b712d5c283"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krvr6f--dQqq"
      },
      "source": [
        "filePath = f\"{getcwd()}/../tmp2/\"\n",
        "nltk.data.path.append(filePath)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUFesnEVdaIq"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import twitter_samples \n",
        "\n",
        "from utils import process_tweet, build_freqs"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7cY3LdUdybS"
      },
      "source": [
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ll8W0c8deL-7"
      },
      "source": [
        "test_pos = all_positive_tweets[4000:]\n",
        "train_pos = all_positive_tweets[:4000]\n",
        "test_neg = all_negative_tweets[4000:]\n",
        "train_neg = all_negative_tweets[:4000]\n",
        "\n",
        "train_x = train_pos + train_neg \n",
        "test_x = test_pos + test_neg"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHD7ZfLOeSu0"
      },
      "source": [
        "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
        "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bphnB96eWqz",
        "outputId": "876143f8-3ba0-4212-99bb-974f3fd27add"
      },
      "source": [
        "print(\"train_y.shape = \" + str(train_y.shape))\n",
        "print(\"test_y.shape = \" + str(test_y.shape))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_y.shape = (8000, 1)\n",
            "test_y.shape = (2000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfABTKzfeZmk",
        "outputId": "92d10ad1-3084-4e38-e138-901bb5ba854c"
      },
      "source": [
        "print('This is an example of a positive tweet: \\n', train_x[0])\n",
        "print('\\nThis is an example of the processed version of the tweet: \\n', process_tweet(train_x[0]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is an example of a positive tweet: \n",
            " #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
            "\n",
            "This is an example of the processed version of the tweet: \n",
            " ['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7IFJ6arhWG0"
      },
      "source": [
        "freqs = build_freqs(train_x, train_y)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxUcv6XPfvys"
      },
      "source": [
        "def extract_features(tweet, freqs):\n",
        "    '''\n",
        "    Input: \n",
        "        tweet: a list of words for one tweet\n",
        "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
        "    Output: \n",
        "        x: a feature vector of dimension (1,3)\n",
        "    '''\n",
        "    # process_tweet tokenizes, stems, and removes stopwords\n",
        "    word_l = process_tweet(tweet)\n",
        "    \n",
        "    # 3 elements in the form of a 1 x 3 vector\n",
        "    x = np.zeros((1, 3)) \n",
        "    \n",
        "    #bias term is set to 1\n",
        "    x[0,0] = 1 \n",
        "    \n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    \n",
        "    # loop through each word in the list of words\n",
        "    for word in word_l:\n",
        "        \n",
        "        # increment the word count for the positive label 1\n",
        "        x[0,1] += freqs.get((word,1.0),0) \n",
        "        \n",
        "        # increment the word count for the negative label 0\n",
        "        x[0,2] += freqs.get((word,0.0),0) \n",
        "        \n",
        "    ### END CODE HERE ###\n",
        "    assert(x.shape == (1, 3))\n",
        "    return x"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PM7idNlhJqf"
      },
      "source": [
        "x_train = np.zeros((len(train_x), 3))\n",
        "for i in range(len(train_x)):\n",
        "    x_train[i, :]= extract_features(train_x[i], freqs)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UQx3JkChszL"
      },
      "source": [
        "y_train = train_y"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei9B1Soih9MV"
      },
      "source": [
        "x_test = np.zeros((len(test_x), 3))\n",
        "for i in range(len(test_x)):\n",
        "    x_test[i, :]= extract_features(test_x[i], freqs)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9PvoUkci4Rs"
      },
      "source": [
        "y_test = test_y"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-Y6t1hfenhi"
      },
      "source": [
        "# **Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG1LP8zBegAK"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOQsRP2SfQc9",
        "outputId": "f51e531a-53fd-4c96-97f2-39a362db4dd8"
      },
      "source": [
        "lr.fit(x_train ,y_train)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iNO5WKSh8SV"
      },
      "source": [
        "predictions = lr.predict(x_test)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejUquQALiWs7",
        "outputId": "d5a87dbf-bcf4-435f-c0e8-c3c68c243501"
      },
      "source": [
        "predictions[1070]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzlDKaaYi8TY"
      },
      "source": [
        "# **Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO5vsAwoi2kF",
        "outputId": "76d8a4c2-32a1-429a-98d5-3e8e2dc04173"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "new = np.asarray(y_test)\n",
        "confusion_matrix(predictions,y_test)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[988,   5],\n",
              "       [ 12, 995]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTfQX1JtjHjU",
        "outputId": "b693116c-11fb-44d4-a75d-b28b646c427c"
      },
      "source": [
        "print(classification_report(predictions,y_test))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.99      0.99       993\n",
            "         1.0       0.99      0.99      0.99      1007\n",
            "\n",
            "    accuracy                           0.99      2000\n",
            "   macro avg       0.99      0.99      0.99      2000\n",
            "weighted avg       0.99      0.99      0.99      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}